{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "from typing import List\n",
    "from os.path import join\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_fonts = {\n",
    "        # Use LaTeX to write all text\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"serif\",\n",
    "        # Use 10pt font in plots, to match 10pt font in document\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        # Make the legend/label fonts a little smaller\n",
    "        \"legend.fontsize\": 8,\n",
    "        \"xtick.labelsize\": 8,\n",
    "        \"ytick.labelsize\": 8,\n",
    "}\n",
    "\n",
    "mpl.rcParams.update(nice_fonts)\n",
    "\n",
    "def set_size(width: float = 347.0, fraction: float = 1., subplot: List[int] = [1, 1]):\n",
    "    \"\"\" Set aesthetic figure dimensions to avoid scaling in latex.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    width: float\n",
    "            Width in pts\n",
    "            Default value 347.12354 is textwidth for Springer llncs\n",
    "    fraction: float\n",
    "            Fraction of the width which you wish the figure to occupy\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fig_dim: tuple\n",
    "            Dimensions of figure in inches\n",
    "\n",
    "    From: https://jwalton.info/Embed-Publication-Matplotlib-Latex/\n",
    "    \"\"\"\n",
    "    # Width of figure\n",
    "    fig_width_pt = width * fraction\n",
    "\n",
    "    # Convert from pt to inches\n",
    "    inches_per_pt = 1 / 72.27\n",
    "\n",
    "    # Golden ratio to set aesthetic figure height\n",
    "    golden_ratio = (5**.5 - 1) / 2\n",
    "\n",
    "    # Figure width in inches\n",
    "    fig_width_in = fig_width_pt * inches_per_pt\n",
    "    # Figure height in inches\n",
    "    fig_height_in = fig_width_in * golden_ratio * (subplot[0] / subplot[1])\n",
    "\n",
    "    fig_dim = (fig_width_in, fig_height_in)\n",
    "\n",
    "    return fig_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    return pickle.load( open( '%s_ultimate_perf_dict.pickle' % dataset, 'rb' ) ), pd.read_csv( '%s_bin_infos.csv' % dataset )\n",
    "\n",
    "path = ''\n",
    "prefix = ''\n",
    "results = {}\n",
    "for dataset in ['abalone', 'concreteStrength', 'delta_ailerons', 'boston',\n",
    "                'available_power', 'servo', 'bank8FM', 'machineCpu', 'airfoild',\n",
    "                'a2', 'a3', 'a1', 'cpu_small', 'acceleration', 'maximal_torque',\n",
    "                'a4', 'a5', 'a7', 'fuel_consumption_country', 'a6',\n",
    "                'normal', 'dnormal', 'pareto', 'rpareto']:\n",
    "    results[dataset] = load_data(prefix + dataset, path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_mixed(l):\n",
    "    other_types = [rk for rk in l if type(rk[1]) != float]\n",
    "    sorted_floats = sorted([rk for rk in l if type(rk[1]) == float])\n",
    "    return sorted_floats + other_types    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_sig_str(model):\n",
    "    return str(model) + ' sig.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bin_rank_mapping(dataset_bin_info):\n",
    "    dataset_bin_info = dataset_bin_info.sort_values(by=['count'])\n",
    "    \n",
    "    # Create mappings from bin to bin rank and vice versa\n",
    "    bin_to_rank = {}\n",
    "    rank_to_bin = {}\n",
    "    for i, bin_row in enumerate(dataset_bin_info.iterrows()):\n",
    "        bin_to_rank[(bin_row[1]['bin_low'], bin_row[1]['bin_high'])] = i\n",
    "        rank_to_bin[i] = (bin_row[1]['bin_low'], bin_row[1]['bin_high'])\n",
    "        \n",
    "    return bin_to_rank, rank_to_bin   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'rmse'\n",
    "# metric = 'mean_absolute_error'\n",
    "fraction = 1.4\n",
    "models = [a/10 for a in list(range(0,21,1))]\n",
    "datasets = ['normal', 'dnormal', 'pareto', 'rpareto']\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=False, figsize=set_size(fraction=fraction, subplot=[2, 2]))\n",
    "linestyles = ['-', '--', ':']\n",
    "\n",
    "for i, dataset in enumerate(datasets):\n",
    "    res, bin_infos = results[dataset]\n",
    "    bin_infos = bin_infos.sort_values(by=['count'])\n",
    "    \n",
    "    # Create mappings from bin to bin rank and vice versa\n",
    "    bin_to_rank, rank_to_bin = create_bin_rank_mapping(bin_infos)\n",
    "\n",
    "    for bin_rank in range(len(bin_infos)):\n",
    "        b = rank_to_bin[bin_rank]\n",
    "        xs = sorted(models)\n",
    "        ys = [res[metric][b][(m, m)][0] for m in xs]\n",
    "        row = i//2\n",
    "        col = i%2\n",
    "        axs[row][col].plot(xs, ys, label=f'Bin Rank {int(bin_rank)+1}', color=str(1/(bin_rank+1.5)), linestyle=linestyles[bin_rank % len(linestyles)])\n",
    "        axs[row][col].set_title(dataset)\n",
    "        axs[row][col].set_xticks(xs[::5])\n",
    "\n",
    "        if i in [0, 2]:\n",
    "            axs[row][col].set_ylabel('RMSE')\n",
    "        if i in [2, 3]:\n",
    "            axs[row][col].set_xlabel('$\\\\alpha$')\n",
    "\n",
    "axs[0][0].legend(ncol=1, fontsize='xx-small')\n",
    "plt.subplots_adjust(hspace=0.25)\n",
    "\n",
    "fig.savefig(join('..', 'plots', 'synth_datasets_results_separate.pdf'), format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth = False\n",
    "\n",
    "metric = 'rmse'\n",
    "# metric = 'mean_absolute_error'\n",
    "fraction = 0.55\n",
    "\n",
    "if synth:\n",
    "    models = [a/10 for a in list(range(0,21,1))]\n",
    "    datasets = ['normal', 'dnormal', 'pareto', 'rpareto']\n",
    "    # Check significance per model only against the baseline of doing nothing\n",
    "    sig_against_all = False\n",
    "    # Show only significant wins\n",
    "    show_only_sig_wins = False\n",
    "    ignore_sig = True\n",
    "    remove_empty_from_legend = True\n",
    "    legend_cols = 5\n",
    "    edge_colors = [None, 'gray', 'gray']\n",
    "else:\n",
    "    models = [0.0, 1.0, '{SMOGN}']\n",
    "    # models = [0.0, 1.0, '{SMOGN_DW}']\n",
    "    datasets = ['abalone', 'concreteStrength', 'delta_ailerons', 'boston',\n",
    "                'available_power', 'servo', 'bank8FM', 'machineCpu', 'airfoild',\n",
    "                'a2', 'a3', 'a1', 'cpu_small', 'acceleration', 'maximal_torque',\n",
    "                'a4', 'a5', 'a7', 'fuel_consumption_country', 'a6']\n",
    "    # Check significance per model against all other models\n",
    "    sig_against_all = True\n",
    "    # Show both significant and insignificant wins\n",
    "    show_only_sig_wins = False\n",
    "    ignore_sig = False\n",
    "    remove_empty_from_legend = False\n",
    "    legend_cols = 3\n",
    "    edge_colors = [None]\n",
    "        \n",
    "wins_per_bin_rank = {0: [], 1: [], 2: [], 3: [], 4: []}\n",
    "# wins_per_bin_rank looks like this: {0: [0.0, 0.5, 0.0, 1.0, 'SMOGN', 0.0, ...]}\n",
    "for dataset in datasets:\n",
    "    res, bin_infos = results[dataset]\n",
    "    bin_infos = bin_infos.sort_values(by=['count'])\n",
    "    \n",
    "    # Create mappings from bin to bin rank and vice versa\n",
    "    bin_to_rank, rank_to_bin = create_bin_rank_mapping(bin_infos)\n",
    "        \n",
    "    for bin_rank in range(len(bin_infos)):\n",
    "        b = rank_to_bin[bin_rank]\n",
    "        model_to_score = {}\n",
    "        for m in models:\n",
    "            model_to_score[m] = res[metric][b][(m, m)][0]\n",
    "            \n",
    "        if all([math.isnan(score) for score in model_to_score.values()]):\n",
    "            best_model = 'No Datapoints'\n",
    "            significant = [False]\n",
    "        else:\n",
    "            \n",
    "            while True:\n",
    "                best_model = min(model_to_score, key=model_to_score.get)\n",
    "                if ignore_sig:\n",
    "                    significant = [False]\n",
    "                    break\n",
    "                if sig_against_all:\n",
    "                    # Check if significant against all other models\n",
    "                    significant = [res[metric][b][(best_model, other_model)][6] for other_model in models if best_model != other_model]\n",
    "                else:\n",
    "                    # Check if significant against no method\n",
    "                    significant = [res[metric][b][(best_model, 0.0)][6]]\n",
    "                if show_only_sig_wins:\n",
    "                    if significant:\n",
    "                        break\n",
    "                        \n",
    "                    model_to_score[best_model] = None\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "        if bin_rank == 0:\n",
    "            print('bin rank 0 at', dataset, 'won by', best_model)\n",
    "\n",
    "        best_model_str = model_sig_str(best_model) if all(significant) else str(best_model)\n",
    "        wins_per_bin_rank[bin_rank].append(best_model_str)\n",
    "        \n",
    "counted_wins = {br: Counter(wins_per_bin_rank[br]) for br in wins_per_bin_rank.keys()}\n",
    "print(counted_wins)\n",
    "\n",
    "def hor_bar_plot(results, category_names, category_colors=None, frac=1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    results : dict\n",
    "        A mapping from question labels to a list of answers per category.\n",
    "        It is assumed all lists contain the same number of entries and that\n",
    "        it matches the length of *category_names*.\n",
    "    category_names : list of str\n",
    "        The category labels.\n",
    "    \"\"\"\n",
    "    labels = list(results.keys())\n",
    "    data = np.array(list(results.values()))\n",
    "    data_cum = data.cumsum(axis=1)\n",
    "    if category_colors is None:\n",
    "        cmap = 'viridis'\n",
    "        category_colors = plt.get_cmap(cmap)(\n",
    "            np.linspace(0.0, 1.0, data.shape[1]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=set_size(fraction=frac))\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlim(0, np.sum(data, axis=1).max())\n",
    "    \n",
    "    ax.set_xticks([]) \n",
    "    \n",
    "    ax.set_ylabel('Bin Ranks')\n",
    "    \n",
    "    hatch_styles = [None]\n",
    "    line_styles = ['-', '--', '-']\n",
    "\n",
    "    for i, (colname, color) in enumerate(zip(category_names, category_colors)):\n",
    "        widths = data[:, i]\n",
    "        starts = data_cum[:, i] - widths\n",
    "        ax.barh(labels, widths, left=starts, height=0.5, edgecolor=edge_colors[i%len(edge_colors)], linestyle=line_styles[i%len(line_styles)],# fill=False,\n",
    "                label=colname, color=color, hatch=hatch_styles[i%len(hatch_styles)])\n",
    "        xcenters = starts + widths / 2\n",
    "\n",
    "        r, g, b, _ = color\n",
    "        text_color = 'white' if r * g * b < 0.5 else 'darkgrey'\n",
    "        for y, (x, c) in enumerate(zip(xcenters, widths)):\n",
    "            if c != 0:\n",
    "                ax.text(x, y, str(int(c)), ha='center', va='center',\n",
    "                        color=text_color)\n",
    "    ax.legend(ncol=legend_cols ,bbox_to_anchor=(0.5, 1), loc='lower center', fontsize='xx-small')\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "nice_names = {\n",
    "    '0.0': 'None',\n",
    "#     '1.0': '$\\\\alpha = 1.0$',\n",
    "    '1.0': 'DenseLoss',\n",
    "    '{SMOGN}': 'SMOGN',\n",
    "    '{SMOGN_DW}': 'SMOGN-DW',\n",
    "}\n",
    "\n",
    "category_names = []\n",
    "nice_category_names = []\n",
    "for m in models:\n",
    "    if not show_only_sig_wins:\n",
    "        category_names.append(str(m))\n",
    "    if not ignore_sig:\n",
    "        category_names.append(model_sig_str(m))\n",
    "    if synth:\n",
    "        if not show_only_sig_wins:\n",
    "            nice_category_names.append(str(m))\n",
    "        if not ignore_sig:\n",
    "            nice_category_names.append(model_sig_str(str(m)))\n",
    "    else:\n",
    "        if not show_only_sig_wins:\n",
    "            nice_category_names.append(nice_names[str(m)])\n",
    "        if not ignore_sig:\n",
    "            nice_category_names.append(model_sig_str(nice_names[str(m)]))\n",
    "\n",
    "if synth:\n",
    "    category_colors = None\n",
    "else:\n",
    "    sig_a = 1.0\n",
    "    insig_a = 0.5\n",
    "    category_colors = [(0.12,0.47,0.7,insig_a), (0.12,0.47,0.7,sig_a), (0.0,0.0,0.0,insig_a), (0.0,0.0,0.0,sig_a), (1.0,0.5,0.05,insig_a), (1.0,0.5,0.05,sig_a), (0.5,0.5,0.05,insig_a), (0.5,0.5,0.05,sig_a)]\n",
    "\n",
    "bin_names = {\n",
    "    0: '1',\n",
    "    1: '2',\n",
    "    2: '3',\n",
    "    3: '4',\n",
    "    4: '5',\n",
    "}\n",
    "\n",
    "res_to_plot = {}\n",
    "for br, win_counts in counted_wins.items():\n",
    "    res_to_plot[bin_names[br]] = []\n",
    "    for cn in category_names:\n",
    "        wc = win_counts[cn] if cn in win_counts.keys() else 0\n",
    "        res_to_plot[bin_names[br]].append(wc)\n",
    "        \n",
    "# Remove models that won't show up in plot\n",
    "if remove_empty_from_legend:\n",
    "    win_indices_to_remove = set()\n",
    "    for i, m in enumerate(category_names):\n",
    "        bin_wins = 0\n",
    "        for br, wins in res_to_plot.items():\n",
    "            bin_wins += wins[i]\n",
    "\n",
    "        if bin_wins == 0:\n",
    "            category_names[i] = None\n",
    "            nice_category_names[i] = None\n",
    "            for br, wins in res_to_plot.items():\n",
    "                win_indices_to_remove.add(i)\n",
    "\n",
    "    category_names = [cn for cn in category_names if cn is not None]\n",
    "    nice_category_names = [cn for cn in nice_category_names if cn is not None]\n",
    "    for br, wins in res_to_plot.items():\n",
    "        for i in sorted(win_indices_to_remove, reverse=True):\n",
    "            del res_to_plot[br][i]\n",
    "\n",
    "fig, ax = hor_bar_plot(res_to_plot, nice_category_names, category_colors, frac=fraction)\n",
    "if synth:\n",
    "    ax.text(-0.8, 0, 'Least', fontsize='x-small')\n",
    "    ax.text(-0.9, 0.25, 'common', fontsize='x-small')\n",
    "    ax.text(-0.8, 3.95, 'Most', fontsize='x-small')\n",
    "    ax.text(-0.9, 4.25, 'common', fontsize='x-small')\n",
    "else:\n",
    "    ax.text(-4.9, 0, 'Least', fontsize='x-small')\n",
    "    ax.text(-5.7, 0.25, 'common', fontsize='x-small')\n",
    "    ax.text(-4.9, 3.95, 'Most', fontsize='x-small')\n",
    "    ax.text(-5.7, 4.25, 'common', fontsize='x-small')\n",
    "plot_name = 'synth_datasets_results.pdf' if synth else prefix + 'real_datasets_results.pdf'\n",
    "fig.savefig(join('..', 'plots', plot_name), format='pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}